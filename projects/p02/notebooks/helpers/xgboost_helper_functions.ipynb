{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import date\n",
    "from fastnumbers import isfloat, isint\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dir_train = '../../data'\n",
    "dir_models = '../../models' \n",
    "\n",
    "mappings = {\n",
    "    'career': 0,\n",
    "    'theory_and_practice': 1,\n",
    "    'deep_learning': 2,\n",
    "    'lang_python': 3,\n",
    "    '_meetings': 4,\n",
    "    'kaggle_crackers': 5,\n",
    "    'big_data': 6,\n",
    "    'lang_r': 7,\n",
    "    'nlp': 8,\n",
    "    'welcome': 9,\n",
    "    'datasets': 10,\n",
    "    'bayesian': 11\n",
    "}\n",
    "\n",
    "\n",
    "# parameters initialization\n",
    "VALIDATION_SPLIT = 0.1\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_gbm():\n",
    "    data = pd.read_csv(os.path.join(dir_train, 'train_set.csv'), usecols=range(1,11), parse_dates=['timestamp', 'thread_timestamp'])\n",
    "    data = data[\n",
    "        data.channel.isin(['career', 'big_data', 'deep_learning', 'kaggle_crackers',\n",
    "               'lang_python',  'lang_r', 'nlp', 'theory_and_practice', 'welcome', 'bayesian', '_meetings', 'datasets']) &\n",
    "        data.main_msg\n",
    "    ]\n",
    "\n",
    "    date_before = date(2017, 4, 1)\n",
    "    train = data[data['timestamp'] <= date_before]\n",
    "    val = data[data['timestamp'] > date_before]\n",
    "\n",
    "    train_data = train[['channel', 'text']].reset_index()[['channel', 'text']]\n",
    "    train_data['channel'] = train_data.channel.map(mappings)\n",
    "    train_data = train_data.sort_values('channel').reset_index()[['channel', 'text']]\n",
    "\n",
    "    val_data = val[['channel', 'text']].reset_index()[['channel', 'text']]\n",
    "    val_data['channel'] = val_data.channel.map(mappings)\n",
    "    val_data = val_data.sort_values('channel').reset_index()[['channel', 'text']]\n",
    "\n",
    "    train_data.text = train_data.text.astype(str)\\\n",
    "        .apply(lambda x: re.sub('(<\\S+>:?)|(\\s?:\\S+:\\s?)|(&gt;)|([\\w\\.]*@[\\w\\.]*)', ' ', x))\\\n",
    "        .apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "    train_data = train_data[~train_data.text.apply(lambda x: isfloat(x) or isint(x) or len(x) < 20)]\n",
    "\n",
    "    val_data.text = val_data.text.astype(str)\\\n",
    "        .apply(lambda x: re.sub('(<\\S+>:?)|(\\s?:\\S+:\\s?)|(&gt;)|([\\w\\.]*@[\\w\\.]*)', ' ', x))\\\n",
    "        .apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "    val_data = val_data[~val_data.text.apply(lambda x: isfloat(x) or isint(x) or len(x) < 20)]\n",
    "\n",
    "    train_text = train_data['text'].astype(str).apply(lambda x: x.lower())\n",
    "    train_labels =  np.asarray(train_data['channel'], dtype='int8')\n",
    "\n",
    "    val_text = val_data['text'].astype(str).apply(lambda x: x.lower())\n",
    "    val_labels = np.asarray(val_data['channel'], dtype='int8')\n",
    "    \n",
    "    return train_text, val_text, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_text, val_text):\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'char', max_features = 1000000, ngram_range = (1, 4))\n",
    "    train_matrix = vectorizer.fit_transform(train_text)\n",
    "    val_matrix = vectorizer.transform(val_text)\n",
    "    return train_matrix, val_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_xgb(train_matrix, val_matrix, train_labels, val_labels, num_classes):\n",
    "    xgb_train = xgb.DMatrix(train_matrix, label=train_labels)\n",
    "    xgb_val = xgb.DMatrix(val_matrix, label=val_labels)\n",
    "\n",
    "    params = {\n",
    "        'eta': 0.1, \n",
    "        'seed': 42, \n",
    "        'subsample': 0.7, \n",
    "        'colsample_bytree': 0.7,\n",
    "        'objective': 'multi:softmax', \n",
    "        'max_depth': 7, \n",
    "        'min_child_weight': 1,\n",
    "        'num_class': num_classes,\n",
    "        'eval_metric': 'merror' \n",
    "    }\n",
    "\n",
    "    eval_matrix = [(xgb_val, 'xgb_val')]\n",
    "\n",
    "    final_gb = xgb.train(params, xgb_train, num_boost_round = 1, evals = eval_matrix, early_stopping_rounds=20,\n",
    "                        verbose_eval=5)\n",
    "    return final_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    with open(os.path.join(dir_models, '{0}.pickle'.format(name)), 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(name):\n",
    "    with open(os.path.join(dir_models, '{0}.pickle'.format(name)), 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
