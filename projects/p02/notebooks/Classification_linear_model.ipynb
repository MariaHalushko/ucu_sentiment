{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "import nltk\n",
    "import stop_words\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score, StratifiedKFold, ParameterGrid\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datetime import date\n",
    "import fastnumbers\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train_set.csv', usecols=range(1,11),  parse_dates=['timestamp', 'thread_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top 12 channels\n",
    "data =data[data.channel.isin(['career', 'big_data', 'deep_learning', 'kaggle_crackers', \n",
    "           'lang_python',  'lang_r', 'nlp', 'theory_and_practice', 'welcome', 'bayesian', '_meetings', 'datasets']) \n",
    "           & data.main_msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels for channels\n",
    "mappings = {\n",
    "    'career': 0,\n",
    "    'theory_and_practice': 1,\n",
    "    'deep_learning': 2,\n",
    "    'lang_python': 3,\n",
    "    '_meetings': 4,\n",
    "    'kaggle_crackers': 5,\n",
    "    'big_data': 6,\n",
    "    'lang_r': 7,\n",
    "    'nlp': 8,\n",
    "    'welcome': 9,\n",
    "    'datasets': 10,\n",
    "    'bayesian': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping labels to channels\n",
    "data['channel'] = data.channel.map(mappings)\n",
    "data = data.sort_values('channel').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude messages w/o text\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on data and data val\n",
    "date_before = date(2017, 4, 1)\n",
    "train = data[data['timestamp'] < date_before]\n",
    "val = data[data['timestamp'] > date_before]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[['channel', 'text']].reset_index()[['channel', 'text']]\n",
    "train_data = train_data.sort_values('channel').reset_index()[['channel', 'text']]\n",
    "\n",
    "val_data = val[['channel', 'text']].reset_index()[['channel', 'text']]\n",
    "val_data = val_data.sort_values('channel').reset_index()[['channel', 'text']]\n",
    "\n",
    "from fastnumbers import isfloat, isint\n",
    "train_data = train_data[~train_data.text.apply(lambda x: isfloat(x) or isint(x) or len(x) < 20)]\n",
    "val_data = val_data[~val_data.text.apply(lambda x: isfloat(x) or isint(x) or len(x) < 20)]\n",
    "\n",
    "train_text = train_data['text'].astype(str)\n",
    "train_labels =  np.asarray(train_data['channel'], dtype='int8')\n",
    "\n",
    "val_text = val_data['text'].astype(str)\n",
    "val_labels = np.asarray(val_data['channel'], dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# library for lemmatization and stop_words\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude spec symbols\n",
    "train_text = train_text\\\n",
    "    .apply(lambda x: re.sub('(<\\S+>:?)|(\\s?:\\S+:\\s?)|(&gt;)|([\\w\\.]*@[\\w\\.]*)', ' ', x))\\\n",
    "    .apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "    \n",
    "val_text = val_text\\\n",
    "    .apply(lambda x: re.sub('(<\\S+>:?)|(\\s?:\\S+:\\s?)|(&gt;)|([\\w\\.]*@[\\w\\.]*)', ' ', x))\\\n",
    "    .apply(lambda x: re.sub('\\s+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without tuning accuracy_score = 50.81%\n",
    "# accuracy_score = 53.81%\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer = 'char', max_features = 1000000, \n",
    "                                                       ngram_range = (1, 4))),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(),n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000000, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf...ti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=-1))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_text, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000000, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf...ti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=-1))])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier for data with lemmatization and w/o stop_word - accuracy score = 51%\n",
    "#classifier.fit([\" \".join(i) for i in train_text_lem], train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.decision_function(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  2,  0, ..., 11,  2,  1], dtype=int8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = np.exp(predicted) / np.sum(np.exp(predicted), axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Но новость от этого сильно лучше не становится \n",
       "1                               Баян, конечно, но в тему \n",
       "2                              А что там под звездочкой? \n",
       "3           для таких случаев нужен эмоджи \"пикап-мастер\"\n",
       "4       это еще ничего, проблема будет, если они тебя ...\n",
       "5                              но я им ничего не высылал \n",
       "6        Мы тщательно рассмотрели все резюме, направле...\n",
       "8        - что-то не пойму, а что же у них тогда есть,...\n",
       "9       в требованиях вакансии \"Java SE 6 или 7\", ниче...\n",
       "10      ну конечно, это же трактор, все сразу должны б...\n",
       "11      в описании компании: Быстрорастущая, развивающ...\n",
       "12       ну джависты хотят прийти в дс и не потерять в...\n",
       "13      она, скорее всего, заплатила за этот текст пар...\n",
       "14      А, если сами начинают придумывать, то получает...\n",
       "15      а меня вот специалистом по компьютер вижн зову...\n",
       "16      но я к тому, что раньше мне только эйчары из м...\n",
       "17      чо, кстати, в среду в райском пирожке завтрак ...\n",
       "18                      У них там питон и скала тоже есть\n",
       "19                          В прод надо писать на питоне \n",
       "20      Не знаю, сарказм это или нет, это к обсуждению...\n",
       "22      Сегодня меня даже по java core погоняли, давно...\n",
       "23      Потихоньку хожу по собеседованиям, везде, с ке...\n",
       "24                                  Немного в этот канал \n",
       "25                               apk еще, может там троян\n",
       "26      давайте вы под свои впн-утехи отдельный чатик ...\n",
       "29      В связи с сегодняшними изменениями политики в ...\n",
       "30      а вот это уже гномики, которые полезны в реаль...\n",
       "31       Так же и тут можно прикинуться серьезным спецом \n",
       "33      Ну норм, если есть желание им заниматься, можн...\n",
       "34      Мне последнее время говорят \"для специалиста в...\n",
       "                              ...                        \n",
       "8830    никто внутренностями Probabilistic programming...\n",
       "8831                                                     \n",
       "8832    По мере того, как различные составляющие этой ...\n",
       "8833    Это просто язык и немного методологии для того...\n",
       "8834    Байесовские методы это не какая-то параллельна...\n",
       "8835    Хочется разобраться, но непонятно пока зачем э...\n",
       "8836    Понятно, что можно интерпретировать всякие рид...\n",
       "8837    Скажите, а есть примеры success story задач/ал...\n",
       "8838    Наткнулся на интересную работу, там успешно уч...\n",
       "8839    Казалось бы 1) максимизируется ELBO, ADVI прек...\n",
       "8840    как с баесовской точки зрения подходить к филь...\n",
       "8841                                     релизнул Gelato \n",
       "8842          Two Methods For Wild Variational Inference \n",
       "8843    У меня нет уверенности что я всё правильно сде...\n",
       "8844    вот такую в оперсорсе где можно б получить? а ...\n",
       "8845                             прикольная тут анимация.\n",
       "8846                                                     \n",
       "8847    Если я рассмотрю бесконечную смесь half-Normal...\n",
       "8848    Есть поток событий, с координатами. Пусть коор...\n",
       "8849    гайз, а поясните, пожалуйста, для как бы заюза...\n",
       "8850    И я брал фичами исходный ряд, плюс эвристики (...\n",
       "8851    Оказывается в ноябре SVGD прикрутили к задаче ...\n",
       "8852                                                     \n",
       "8853                                    в чатике не было \n",
       "8854    хороший intro обзор вариационных базовых модел...\n",
       "8855                                                     \n",
       "8856                       прикручивается ли к SVGD aevb?\n",
       "8857    Stochastic Gradient Descent as Approximate Bay...\n",
       "8858                              может у тебя есть идеи?\n",
       "8859    Проще предположить, что фичи все правильные, н...\n",
       "Name: text, Length: 8200, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53817073170731711"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(['как у дата сайнтиста зарплата в германии'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int8)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(['какие лучшие подходы для сентимент анализа'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int8)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(['почему поламался хадуп'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int8)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(['кто-то принимает участет в соревоаниях'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1544</td>\n",
       "      <td>90</td>\n",
       "      <td>132</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>457</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>486</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>7</td>\n",
       "      <td>264</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>92</td>\n",
       "      <td>687</td>\n",
       "      <td>86</td>\n",
       "      <td>41</td>\n",
       "      <td>290</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>510</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>493</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>141</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2060</td>\n",
       "      <td>881</td>\n",
       "      <td>1199</td>\n",
       "      <td>871</td>\n",
       "      <td>179</td>\n",
       "      <td>1731</td>\n",
       "      <td>275</td>\n",
       "      <td>205</td>\n",
       "      <td>373</td>\n",
       "      <td>212</td>\n",
       "      <td>142</td>\n",
       "      <td>72</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1     2    3    4     5    6    7    8    9   10  11   All\n",
       "True                                                                         \n",
       "0          1544   90   132   57    7   457   28   12   36   12   15   9  2399\n",
       "1           134  486   150  146    7   264   28   18   72    2   19  22  1348\n",
       "2           167   92   687   86   41   290   24   55   84    1   21  19  1567\n",
       "3            42  106   110  510    5    78   33   24   22    2    4   4   940\n",
       "4            87   17    33    8  108   104    7    8    9    2    6   4   393\n",
       "5            40   35    44   19    4   493    9    3   13    1   10   1   672\n",
       "6            17   15     8   13    1    15  141    8    1    0    3   1   223\n",
       "7             5   14    10   18    0    10    3   74    4    0    0   1   139\n",
       "8             9    8    15    6    1    14    1    2  123    0   17   1   197\n",
       "9            12    8     7    3    5     2    1    1    3  192    1   1   236\n",
       "10            2    7     2    5    0     4    0    0    6    0   46   0    72\n",
       "11            1    3     1    0    0     0    0    0    0    0    0   9    14\n",
       "All        2060  881  1199  871  179  1731  275  205  373  212  142  72  8200"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix error\n",
    "pd.crosstab(predicted, val_labels, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
